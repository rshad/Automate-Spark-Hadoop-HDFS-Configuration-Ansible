# first of all, we create hadoop user, so this user will be the one used to configure Hadoopa and HDFS
#- name: creating hadoop user
#  user:
#    name: hadoop
#    password: "{{ hadoop }}"
#    state: present
#    shell: /bin/bash    
#    system: no
#    createhome: yes
#    home: /home/hadoop

# -------------------------------- Installing Hadoop ------------------------------------------ #

# Note:  We do not need to donwload the java package from internet, we have our own already downloaded.
#- name: Extracting Hadoop package
#
#  unarchive:
#    src: "{{ hadoop_package_file }}"
#    dest: "{{ download_folder }}"
#  when: inventory_hostname in groups['masters']
#
#- name: "Changing the hadoop folder name from {{ hadoop_folder_path_name_old }} to {{ download_folder }}/{{ hadoop_folder_name_new }}"
#
#  command: "mv {{ hadoop_folder_path_name_old }}  {{ download_folder }}/{{ hadoop_folder_name_new }}"
#  when: inventory_hostname in groups['masters']
#
#- name: Copying hadoop/ folder to the slaves hosts ...
#  synchronize:
#    src: "{{ download_folder }}/{{ hadoop_folder_name_new }}"
#    dest: "{{ download_folder }}/"
#  when: inventory_hostname in groups['slaves']  

# Setting the required path for hadoop ...
#- name: Writing Hadoop Path's into /home/hadoop/.bashrc ...
#  lineinfile:
#    path: /home/hadoop/.bashrc
#    line: "{{ item }}"

#  become: yes
#  become_user: hadoop

#  with_items: 
#    - export HADOOP_PREFIX=/opt/hadoop
#    - export HADOOP_HOME=$HADOOP_PREFIX
#    - export HADOOP_COMMON_HOME=$HADOOP_PREFIX
#    - export HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoop
#    - export HADOOP_HDFS_HOME=$HADOOP_PREFIX
#    - export HADOOP_MAPRED_HOME=$HADOOP_PREFIX
#    - export HADOOP_YARN_HOME=$HADOOP_PREFIX
#    - export PATH=$PATH:$HADOOP_PREFIX/sbin:$HADOOP_PREFIX/bin

# Applying the changes
#- name: applying the changes ...
#  shell: source ~/.bashrc
#  become: yes
#  become_user: hadoop

# -------------------------------- Configuring Hadoop ------------------------------------------ #

#- name: Installing lxml python library ...
#  command: pip install lxml

#- name: Modifying the file /opt/hadoop/etc/hadoop/core-site.xml  ...
#  xml:
#    path: /opt/hadoop/etc/hadoop/core-site.xml
#    xpath: /configuration/property        
#    value:

#- name: Modifying the file /opt/hadoop/etc/hadoop/core-site.xml  ...
#  xml:
#    path: /opt/hadoop/etc/hadoop/core-site.xml
#    xpath: /configuration/property/name
#    value: fs.defaultFS

#- name: Modifying the file /opt/hadoop/etc/hadoop/core-site.xml  ...
#  xml:
#    path: /opt/hadoop/etc/hadoop/core-site.xml
#    xpath: /configuration/property/value
#    value: hdfs://central-machine:9000/

#- name: Creating the required folders for Hadoop ...
#  command: "{{ item }}"
#  args: 
#    warn: False  
#  with_items:
#    - chown hadoop /opt/hadoop/ -R 
#    - chgrp hadoop /opt/hadoop/ -R
#    - mkdir /home/hadoop/datanode
#    - chown hadoop /home/hadoop/datanode/
#    - chgrp hadoop /home/hadoop/datanode/


- name: Modifying the file /opt/hadoop/etc/hadoop/hdfs-site.xml  ...
  xml:
    path: /opt/hadoop/etc/hadoop/hdfs-site.xml
    xpath: /configuration
    

